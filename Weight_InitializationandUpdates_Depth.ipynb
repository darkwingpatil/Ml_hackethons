{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/darkwingpatil/Ml_hackethons/blob/main/Weight_InitializationandUpdates_Depth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYWmevIvTDpR"
      },
      "source": [
        "# Advanced Certification in AIML\n",
        "## A Program by IIIT-H and TalentSprint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4FCyw-x2uMj"
      },
      "source": [
        "## Learning Objective"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIQ3DCiq2yC8"
      },
      "source": [
        "At the end of the experiment, you will be to :\n",
        "\n",
        "1. Understand the role of the momentum parameter\n",
        "2. Observe what happens when momentum value is set to high or low\n",
        "3. Different weight initialization techniques like Xavier, he"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8oaZCpUoFtU",
        "cellView": "form"
      },
      "source": [
        "#@title Experiment Explanation Video\n",
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\"\"\"<video width=\"800\" height=\"300\" controls>\n",
        "  <source src=\"https://cdn.talentsprint.com/talentsprint1/archives/sc/aiml/weight_intilizations.mp4\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOW-MICx26k2"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRsmWX823C0F"
      },
      "source": [
        "### Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1Uib7-L2_4S"
      },
      "source": [
        "\n",
        "\n",
        "The dataset used for this experiment is CIFAR-100. It  has 100 classes which contains 600 images for each class. There are 500 training images and 100 testing images per class. These 100 classes are grouped into 20 superclasses. Each image comes with the class and superclass it belongs to.\n",
        "\n",
        "Here is the list of classes in the CIFAR-100:\n",
        "\n",
        "| Superclass \t | Classes|\n",
        "|--------------------|-------------|\n",
        "|aquatic mammals | \tbeaver, dolphin, otter, seal, whale |\n",
        "|fish |\taquarium fish, flatfish, ray, shark, trout |\n",
        "|flowers| \torchids, poppies, roses, sunflowers, tulips |\n",
        "|food containers| \tbottles, bowls, cans, cups, plates|\n",
        "|fruit and vegetables| \tapples, mushrooms, oranges, pears, sweet peppers|\n",
        "|household electrical devices | clock, computer keyboard, lamp, telephone, television|\n",
        "|household furniture| \tbed, chair, couch, table, wardrobe|\n",
        "|insects | \tbee, beetle, butterfly, caterpillar, cockroach |\n",
        "|large carnivores| \tbear, leopard, lion, tiger, wolf|\n",
        "|large man-made outdoor things |\tbridge, castle, house, road, skyscraper|\n",
        "|large natural outdoor scenes |\tcloud, forest, mountain, plain, sea|\n",
        "|large omnivores and herbivores |\tcamel, cattle, chimpanzee, elephant, kangaroo|\n",
        "|medium-sized mammals |\tfox, porcupine, possum, raccoon, skunk|\n",
        "|non-insect invertebrates|\tcrab, lobster, snail, spider, worm|\n",
        "|people| \tbaby, boy, girl, man, woman|\n",
        "|reptiles |\tcrocodile, dinosaur, lizard, snake, turtle|\n",
        "|small mammals| \thamster, mouse, rabbit, shrew, squirrel |\n",
        "|trees|\tmaple, oak, palm, pine, willow |\n",
        "|vehicles 1 |\tbicycle, bus, motorcycle, pickup truck, train |\n",
        "|vehicles 2 |\tlawn-mower, rocket, streetcar, tank, tractor |\n",
        "\n",
        "\n",
        "\n",
        "The dataset is downloaded from following url :\n",
        "\n",
        "https://www.cs.toronto.edu/~kriz/cifar.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6F_Eqss3aRi"
      },
      "source": [
        "## AI / ML Technique"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFt9zERH3cwx"
      },
      "source": [
        "In this experiment you will see various initialization techniques :\n",
        "\n",
        "\n",
        "*   Zero and Normal Initialization\n",
        "*   Xavier Initialization\n",
        "*   He-et-al Initialization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IV7cJIHX3jEO"
      },
      "source": [
        "### Zero and Normal Initialization\n",
        "\n",
        "1. If you assign all weights to be zero, then all the neurons of all the layers performs the same calculation, giving the same output and there by making whole neural net useless.\n",
        "\n",
        "2. If you assign all weights close to zero but randomly. This helps in breaking symmetry and every neuron is no longer performing the same computation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBrWbXi53ltI"
      },
      "source": [
        "### Xavier Initialization (from the name *Xavier Glorot*)\n",
        "\n",
        "When you intialize weights to some random values in the network, they lead to two problems :\n",
        "\n",
        "1. If weights are assigned with very small values, then the signal or data shrinks as it passes through each layer until it's to  tiny to use.\n",
        "2. If weights re assigned with too large values, then the signal or data grows as it passes through each layer until it becomes massive to use.\n",
        "\n",
        "\n",
        "One good way is to assign the weights from a Gaussian distribution. Obviously this distribution would have zero mean and some finite variance. Let’s consider a linear neuron:\n",
        "\n",
        "                                  y = w1x1 + w2x2 + ... + wNxN + b\n",
        "\n",
        "With each passing layer, we want the variance to remain the same. **This helps us keep the signal from exploding to a high value or vanishing to zero** (Frequently asked interview question). In other words, you need to initialize the weights in such a way that the variance remains the same for x and y. This initialization process is known as Xavier initialization.\n",
        "\n",
        "You can read the original paper [here](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHdGZ_P73oNq"
      },
      "source": [
        "### He-et-al Initialization\n",
        "This method of initialization is similar to Xavier initialization, with the factor multipled by 2. The weights are initialized keeping the size of previous layer in mind. The weights are still random but differ in range depending on the size of previous layer neurons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjsUxBup3vMt"
      },
      "source": [
        "### Momentum\n",
        "\n",
        "\n",
        "While updating weights using backpropagation after every training sample we must supply a learning rate. The learning rate controls the change in weight and bias values for each training iteration.\n",
        "The equation to update weights connecting between two layers is as below :\n",
        "\n",
        "$\\Delta w_{ij} = \\eta * \\frac{\\partial E}{\\partial w_{ij}}$\n",
        "\n",
        "\n",
        "If you choose very low learning rate value, the convergence is very slow. It may take hours or days.\n",
        "\n",
        "If you choose very high learning rate value, you would overshoot the ideal value. Due to which, in the next iteration we would undershoot the value. This would result in increase of time to train the model.\n",
        "\n",
        "Hence, to increase the speed up the training process you use momentum which is present in most of the models.\n",
        "\n",
        "The equation to update weights with momentum at given time 't' is as below:\n",
        "\n",
        "$\\Delta w_{ij} = (\\eta * \\frac{\\partial E}{\\partial w_{ij}}) + (\\gamma * \\Delta w_{ij}^{t-1})$\n",
        "\n",
        "\n",
        "Momentum simply adds a fraction $\\gamma$ of the previous weight update to the current one.\n",
        "When the gradient keeps pointing in the same direction, this will increase the size of the steps taken towards the minimum and when the gradient keeps changing direction, momentum will smooth out the variations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlHZrM8s3uO2"
      },
      "source": [
        "### LeNet Architecture\n",
        "\n",
        "LeNet-5 a pioneering 7-level convolutional network by LeCun et al in 1998, that classifies digits, was applied by several banks to recognise hand-written numbers on checks (cheques) digitized in 32x32 pixel images. The ability to process higher resolution images requires larger and more convolutional layers, so this technique is constrained by the availability of computing resources.\n",
        "\n",
        "![alt text](https://cdn-images-1.medium.com/max/800/0*MU7G1aH1jw-6eFiD.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUmaxUW-rpxU"
      },
      "source": [
        "### Setup Steps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcrXxhfmrpxg"
      },
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"2304145\" #@param {type:\"string\"}"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDAfm706rpxg"
      },
      "source": [
        "#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"7892449987\" #@param {type:\"string\"}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "KvdKENTWrpxh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "74514897-98ee-4e5f-fdb8-cc89fce01b72"
      },
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "import re\n",
        "ipython = get_ipython()\n",
        "\n",
        "notebook= \"U4W18_64_Weight_InitializationandUpdates_A\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\")\n",
        "    from IPython.display import HTML, display\n",
        "    ipython.magic(\"sx pip3 install torch\")\n",
        "    ipython.magic(\"sx pip3 install torchvision\")\n",
        "    ipython.magic(\"sx wget https://cdn.talentsprint.com/aiml/Experiment_related_data/week9/Exp6/config.py\")\n",
        "    ipython.magic(\"sx wget https://cdn.talentsprint.com/aiml/Experiment_related_data/week9/Exp6/utils.py\")\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "\n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "\n",
        "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getWalkthrough() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id,\n",
        "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook, \"feedback_walkthrough\":Walkthrough ,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_inclass_mentor\": Mentor_support}\n",
        "\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://aiml-iiith.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "\n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional\n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "\n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getWalkthrough():\n",
        "  try:\n",
        "    if not Walkthrough:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Walkthrough\n",
        "  except NameError:\n",
        "    print (\"Please answer Walkthrough Question\")\n",
        "    return None\n",
        "\n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer():\n",
        "  try:\n",
        "    if not Answer:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Answer\n",
        "  except NameError:\n",
        "    print (\"Please answer Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getId():\n",
        "  try:\n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup\n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup()\n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId=2304145&recordId=8018\"></script>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup completed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFzdcJA2TDpd"
      },
      "source": [
        "### Importing required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_3rHeQhTDpj"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Importing config.py file\n",
        "import config as cf\n",
        "from utils import *\n",
        "\n",
        "# Importing python packages\n",
        "import os\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCUpCR1JTDpo"
      },
      "source": [
        "# Checking for GPU instance\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Intilizaing the accuracy value as zero\n",
        "best_acc = 0"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiiOuYoDTDps"
      },
      "source": [
        "#### Preparing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqJY6GjbTDpt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba5402a5-17eb-4370-b01c-65ce8c1abafb"
      },
      "source": [
        "print('\\n[Phase 1] : Data Preparation')\n",
        "\n",
        "# Dataset\n",
        "dataset = 'cifar100'\n",
        "\n",
        "# Preparing the dataset\n",
        "transform_train = transforms.Compose(# YOUR CODE HERE: To define the transformations\n",
        "                                     [\n",
        "                                         transforms.ToTensor(),\n",
        "                                         transforms.Normalize(cf.mean[dataset], cf.std[dataset])\n",
        "                                     ]\n",
        ") # mean and std transformation\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(cf.mean[dataset], cf.std[dataset]),\n",
        "])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Phase 1] : Data Preparation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgQYaTkyTDp5"
      },
      "source": [
        "#### Downloading and Loading the dataset\n",
        "\n",
        "The torchvision package consists of popular datasets, model architectures, and common image transformations for computer vision.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NIPyVNwTDp6"
      },
      "source": [
        "num_classes = 100\n",
        "# YOUR CODE HERE: Define number of classes in the dataset"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NKFYS4vTDp_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d3bd41d-f103-4ab5-e480-686b7f5b43df"
      },
      "source": [
        "# Downloading the dataset\n",
        "trainset = torchvision.datasets.CIFAR100(root='data', train=True, download=True, transform=transform_train)\n",
        "testset = torchvision.datasets.CIFAR100(root='data', train=False, download=False, transform=transform_test)\n",
        "\n",
        "# Loading the dataset\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=8)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=8)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169001437/169001437 [00:04<00:00, 35769680.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-100-python.tar.gz to data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzEYmhJLTDqE"
      },
      "source": [
        "#### Let us define the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xjme8iyjTDqF"
      },
      "source": [
        "class LeNet(nn.Module):\n",
        "    def __init__(self, num_classes, init_mode='xavier'):  # Supports 'zero', 'normal', 'xavier', 'he' initializations\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1   = nn.Linear(16*5*5, 120)\n",
        "        self.fc2   = nn.Linear(120, 84)\n",
        "        self.fc3   = nn.Linear(84, num_classes)\n",
        "\n",
        "        if init_mode == 'zero':\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "                    # YOUR CODE HERE: Initialize Weights with zero\n",
        "                    m.weight.data.zero_()\n",
        "                    if m.bias is not None:\n",
        "                      m.bias.data.zero_()\n",
        "                       # YOUR CODE HERE: Initialize bias with zero\n",
        "\n",
        "        if init_mode == 'normal':\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "                    m.weight.data.normal_()\n",
        "                     # YOUR CODE HERE: Initialize elements with random numbers from normal distribution\n",
        "                    if m.bias is not None:\n",
        "                        m.bias.data.normal_()\n",
        "\n",
        "        if init_mode == 'xavier':\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, nn.Conv2d):\n",
        "                    fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                    fan_in = m.kernel_size[0] * m.kernel_size[1] * m.in_channels\n",
        "                    n = fan_in + fan_out\n",
        "                    m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "                    if m.bias is not None:\n",
        "                        m.bias.data.normal_(0, math.sqrt(2. / n))\n",
        "                if isinstance(m, nn.Linear):\n",
        "                    size = m.weight.size()\n",
        "                    fan_out = size[0] # Number of rows\n",
        "                    fan_in = size[1] # Number of columns\n",
        "                    variance = math.sqrt(2.0/(fan_in+fan_out))\n",
        "                    m.weight.data.normal_(0.0, variance)\n",
        "                    if m.bias is not None:\n",
        "                        m.bias.data.normal_(0, variance)\n",
        "\n",
        "        if init_mode == 'he':\n",
        "          for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                # YOUR CODE HERE: Just as above, figure out the mathematical formulation of 'he' initialization and initialize the weights\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "                if m.bias is not None:\n",
        "                  m.bias.data.normal_(0, math.sqrt(2. / n))\n",
        "            if isinstance(m, nn.Linear):\n",
        "                # YOUR CODE HERE: Just as above, figure out the mathematical formulation of 'he' initialization and initialize the weights\n",
        "                size = m.weight.size()\n",
        "                fan_out = size[0] # Number of rows\n",
        "                fan_in = size[1] # Number of columns\n",
        "                variance = math.sqrt(2.0/(fan_in))\n",
        "                m.weight.data.normal_(0.0, variance)\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.normal_(0, variance)\n",
        "\n",
        "\n",
        "    # Forward Pass\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.conv1(x))\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = F.relu(self.conv2(out))\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = F.relu(self.fc1(out))\n",
        "        out = F.relu(self.fc2(out))\n",
        "        out = self.fc3(out)\n",
        "        return(out)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxoH_XmfTDqK"
      },
      "source": [
        "### Training with Xavier init"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thScVAq9TDqK"
      },
      "source": [
        "# Calling the model with Xavier\n",
        "net = LeNet(num_classes, init_mode='xavier') # You rerun this entire experiment alternate values to 'xavier' (check ungraded exercise below)\n",
        "# Checking for GPU instance\n",
        "net = net.to(device)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7-NPduRnuTV"
      },
      "source": [
        "### Defining the Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRQtQpXQTDqP"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "# YOUR CODE HERE: Intiliazing the loss"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gjt5p-s5nqG1"
      },
      "source": [
        "### Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiZgcgFuTDqT"
      },
      "source": [
        "def train(epoch):\n",
        "    # YOUR CODE HERE: To train the network\n",
        "    train_loss=0\n",
        "    correct=0\n",
        "    total=0\n",
        "    net.train()\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        # Coverting inputs and targets intp pytorch variables\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "\n",
        "        size_ = outputs.size()\n",
        "        outputs_ = outputs.view(size_[0], num_classes)\n",
        "\n",
        "        loss = criterion(outputs_, targets)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs_.data, 1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets.data).cpu().sum().item()\n",
        "\n",
        "    # Storing number of epoch, loss and accuracy in a file\n",
        "    train_loss_file.write('%d %.3f %.3f\\n' %(epoch, train_loss/len(trainloader), 100.*correct/total))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT51xH8woWNZ"
      },
      "source": [
        "### Testing the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KHXrvL_TDqX"
      },
      "source": [
        "def test(epoch):\n",
        "    global best_acc\n",
        "    net.eval()\n",
        "\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # Looping over the test data\n",
        "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "\n",
        "        # Coverting inputs and targets intp pytorch variables\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = net(inputs)\n",
        "\n",
        "        # Storing the size of outputs\n",
        "        size_ = outputs.size()\n",
        "\n",
        "        # Reducing the dimenssion\n",
        "        outputs_ = outputs.view(size_[0], num_classes)\n",
        "\n",
        "        # Calculating the loss\n",
        "        loss = criterion(outputs_, targets)\n",
        "\n",
        "        # Calculating the test loss\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        # Predicted values\n",
        "        _, predicted = torch.max(outputs_.data, 1)\n",
        "\n",
        "        # Storing the size of targets\n",
        "        total += targets.size(0)\n",
        "\n",
        "        # Calculating the correct values\n",
        "        correct += predicted.eq(targets.data).cpu().sum().item()\n",
        "\n",
        "        # Printing the data\n",
        "        if batch_idx%30 == 0 or batch_idx == len(testloader)-1:\n",
        "            # printing the progress bar\n",
        "            progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                         % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "    # Printing the validation loss\n",
        "    print('val_loss: ',  test_loss/len(testloader), 'accuracy: ', 100.0*correct/total)\n",
        "    # Storing number of epoch,loss and acuracy in a file\n",
        "    val_loss_file.write('%d %.3f %.3f\\n' %(epoch,  test_loss/len(testloader), 100.*correct/total))\n",
        "\n",
        "    # Save checkpoint.\n",
        "    acc = 100.*correct/total\n",
        "    # Checking for best accuracy\n",
        "    if acc > best_acc:\n",
        "        print('Saving..')\n",
        "        state = {\n",
        "            'net': net,\n",
        "            'acc': acc,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        # Checking for the directory\n",
        "        if not os.path.isdir('../checkpoint'):\n",
        "            # creating the directory\n",
        "            os.mkdir('../checkpoint')\n",
        "        # Saving the data\n",
        "        torch.save(state, '../checkpoint_ckpt.t7')\n",
        "        # Storing the accuracy value\n",
        "        best_acc = acc"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkgjZ2B-TDqd"
      },
      "source": [
        "### Training without momentum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82LN3du2TDqe"
      },
      "source": [
        "experiment = 'no_momentum'\n",
        "\n",
        "# Creating files in write mode\n",
        "train_loss_file = open(experiment+\"train_loss.txt\", \"w\")\n",
        "val_loss_file = open(experiment+\"val_loss.txt\", \"w\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dha64aWkTDql",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "4fc4d78c-6f4d-4bc6-ee8b-38a63b002063"
      },
      "source": [
        "# Optimizer\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0)\n",
        "\n",
        "for epoch in range(0,30):\n",
        "  if epoch == 10:\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "  if epoch ==20:\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)\n",
        "\n",
        "  train(epoch)\n",
        "\n",
        "# YOUR CODE HERE : Train and Test the model for 30 epochs\n",
        "\n",
        "# Closing the values\n",
        "train_loss_file.close()\n",
        "val_loss_file.close()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'torch.optim' has no attribute 'sgd'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-d0493765990e>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torch.optim' has no attribute 'sgd'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg3AopZuTDqq"
      },
      "source": [
        "#### Plotting the Training curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mAj4OtMTDqr"
      },
      "source": [
        "training_curves(experiment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu87uO1fTDqw"
      },
      "source": [
        "### Training with momentum\n",
        "\n",
        "#### Note that momentum is 0 by default in pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh_4FXykTDqz"
      },
      "source": [
        "best_acc = 0\n",
        "# Calling the model\n",
        "net = LeNet(num_classes, init_mode='xavier')\n",
        "# Checking for GPU instance\n",
        "net = net.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZOHn5ozTDq4"
      },
      "source": [
        "experiment = 'with_momentum'\n",
        "# Cretaing files in write mode\n",
        "train_loss_file = open(experiment+\"train_loss.txt\", \"w\")\n",
        "val_loss_file = open(experiment+\"val_loss.txt\", \"w\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BPy7Sl4TDq_"
      },
      "source": [
        "# Optimizer\n",
        "optimizer = # YOUR CODE HERE: Define parameters to train 'with momentum'\n",
        "\n",
        "# Training and Testing the model for 10 epochs\n",
        "for epoch in range(0, 10):\n",
        "    # Training the model\n",
        "    train(epoch)\n",
        "    # Testing the model\n",
        "    test(epoch)\n",
        "\n",
        "# Closing the files\n",
        "train_loss_file.close()\n",
        "val_loss_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRQsw9f5TDrE"
      },
      "source": [
        "#### Plotting the training curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WHQH8bkTDrG"
      },
      "source": [
        "training_curves(experiment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQlJ6Rab4zKr"
      },
      "source": [
        "### Ungraded Exercise 1 : Try with different weight initialization techniques like 'zero', 'normal' and 'he' while calling the LeNet model.\n",
        "\n",
        "\n",
        "**Note :**  When you run the code with 'normal' weight initialization and with momentum you may get NaN values. This is because random initialization, randomly samples values from a normal distribution, and hence higher the probability that some of these random values explodes the forward pass of the network. If you face this, you need to restart the runtime and rerun the experiment. (as this would ensure a new random initialiazation which should enable  the forward pass )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHfHdGCP_n6Y"
      },
      "source": [
        "### Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmvdJ4aNmGjR"
      },
      "source": [
        "#@title State True or False: Xavier initialization ensures to initialize the weights such that neurons won't start training in saturation or dead regions. { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Answer = \"TRUE\" #@param [\"\",\"TRUE\", \"FALSE\"]\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmufjlR-rjv6"
      },
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"Good and Challenging for me\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ7vVuShrjv6"
      },
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"NA\" #@param {type:\"string\"}\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VBk_4VTAxCM"
      },
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"Yes\" #@param [\"\",\"Yes\", \"No\"]\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r35isHfTVGKc"
      },
      "source": [
        "#@title  Experiment walkthrough video? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Walkthrough = \"Didn't use\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH91cL1JWH7m"
      },
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"Somewhat Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8xLqj7VWIKW"
      },
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"Didn't use\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzAZHt1zw-Y-",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5530fe7f-f5c3-4664-8a8c-916908eb116d"
      },
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your submission is successful.\n",
            "Ref Id: 8018\n",
            "Date of submission:  01 Oct 2024\n",
            "Time of submission:  23:28:45\n",
            "View your submissions: https://aiml-iiith.talentsprint.com/notebook_submissions\n"
          ]
        }
      ]
    }
  ]
}