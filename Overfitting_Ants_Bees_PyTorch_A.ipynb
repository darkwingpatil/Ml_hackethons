{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/darkwingpatil/Ml_hackethons/blob/main/Overfitting_Ants_Bees_PyTorch_A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zSWyuZTlYS1"
      },
      "source": [
        "\n",
        "# Advanced Certification in AIML\n",
        "## A Program by IIIT-H and TalentSprint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oU2MBx7JtTyP"
      },
      "source": [
        "## Learning Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot3pfe3AtWaN"
      },
      "source": [
        "At the end of the experiment, you will be able to:\n",
        "\n",
        "* reduce overfitting using regularization method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDtOUGiIbwT2",
        "cellView": "form"
      },
      "source": [
        "#@title Experiment Explanation Video\n",
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\"\"\"<video width=\"850\" height=\"480\" controls>\n",
        "  <source src=\"https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/Walkthrough/Walkthrough_Overfitting_Ants_Bees.mp4\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35RBpSDUtYUm"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVIILnxWtcKA"
      },
      "source": [
        "### Description\n",
        "\n",
        "For this experiment we have choosen a dataset which is subset of Imagenet. We have taken images belonging to ants and bees. The dataset contains 244 training images and 153 validation images.\n",
        "\n",
        "![alt text]( https://cdn.talentsprint.com/aiml/Experiment_related_data/IMAGES/15.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUmaxUW-rpxU"
      },
      "source": [
        "### Setup Steps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcrXxhfmrpxg"
      },
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"2304145\" #@param {type:\"string\"}"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDAfm706rpxg"
      },
      "source": [
        "#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"7892449987\" #@param {type:\"string\"}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "KvdKENTWrpxh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "26557c75-5373-49c9-fac5-c1473c52c116"
      },
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "import re\n",
        "ipython = get_ipython()\n",
        "\n",
        "notebook= \"U3W12_44_Overfitting_Ants_Bees_PyTorch_A\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\")\n",
        "    from IPython.display import HTML, display\n",
        "    ipython.magic(\"sx wget https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/hymenoptera_data.zip\")\n",
        "    ipython.magic(\"sx unzip /content/hymenoptera_data.zip\")\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "\n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "\n",
        "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getWalkthrough() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id,\n",
        "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook, \"feedback_walkthrough\":Walkthrough ,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_inclass_mentor\": Mentor_support}\n",
        "\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://aiml-iiith.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "\n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional\n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "\n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getWalkthrough():\n",
        "  try:\n",
        "    if not Walkthrough:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Walkthrough\n",
        "  except NameError:\n",
        "    print (\"Please answer Walkthrough Question\")\n",
        "    return None\n",
        "\n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer():\n",
        "  try:\n",
        "    if not Answer:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Answer\n",
        "  except NameError:\n",
        "    print (\"Please answer Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getId():\n",
        "  try:\n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup\n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup()\n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId=2304145&recordId=6310\"></script>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup completed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEeo3n0ElYS_"
      },
      "source": [
        "## Importing the required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ydf-Vi2P2r6"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch import optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.functional import F"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKWUSRUQuwmW"
      },
      "source": [
        "## Defining Transformation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPjq8djgJY7v"
      },
      "source": [
        "image_size = (128,128)\n",
        "# Define Transformation for an image\n",
        "transoformation = transforms.Compose([\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.Grayscale(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0.5,0.5)\n",
        "])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SM5nwIvuu2Nw"
      },
      "source": [
        "## Data Loading\n",
        "\n",
        "\n",
        "**torch.utils.data.DataLoader** class represents a Python iterable over a dataset, with following features.\n",
        "\n",
        "1. Batching the data\n",
        "2. Shuffling the data\n",
        "3. Load the data in parallel using multiprocessing workers.\n",
        "\n",
        "\n",
        "The batches of train and test data are provided via data loaders that provide iterators over the datasets to train our models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OxC0CShJZZ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9872f0b8-46fd-4ebb-dd96-1b7f1176506c"
      },
      "source": [
        "batch_size = 100\n",
        "train_set = datasets.ImageFolder('/content/hymenoptera_data/train', transform = transoformation)\n",
        "trainloader = torch.utils.data.DataLoader(train_set, batch_size=100, shuffle=True, num_workers=8)\n",
        "\n",
        "val_set = datasets.ImageFolder('/content/hymenoptera_data/val',transform=transoformation)\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=100, shuffle=True)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEYZoawOppFN"
      },
      "source": [
        "## Defining the Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEhqiDSmfE3C"
      },
      "source": [
        "Neural Networks are inherited from the nn.Module class.\n",
        "\n",
        "Now let us define a neural network. Here we are using two functions \\__init__ and forward function.\n",
        "\n",
        "In the \\__init__  function, we define the layers using the provided modules from the nn package. The forward function is called on the Neural Network for a set of inputs, and it passes that input through the different layers that have been defined.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEJHXJD0jTwD"
      },
      "source": [
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        self.linear1 = nn.Linear(16384,4096)\n",
        "        self.linear2 = nn.Linear(4096,1024)\n",
        "        self.linear3 = nn.Linear(1024,256)\n",
        "        self.linear4 = nn.Linear(256,10)\n",
        "        self.linear5 = nn.Linear(10,2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x.view(x.shape[0],-1)\n",
        "        out = F.relu(self.linear1(out))\n",
        "        out = F.relu(self.linear2(out))\n",
        "        out = F.relu(self.linear3(out))\n",
        "        out = F.relu(self.linear4(out))\n",
        "        out = self.linear5(out)\n",
        "        out = F.log_softmax(out, dim=1)\n",
        "        return out\n",
        "\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nw3kD1Kjqvx_"
      },
      "source": [
        "## Calling the instances of the network\n",
        "\n",
        "Let us declare an object of class model, and make it a CUDA model if CUDA is available:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_5p3NM4S9CR"
      },
      "source": [
        "# Instantiate the model\n",
        "device = torch.device(\"cuda\")\n",
        "# YOUR CODE HERE to instantiate the model and convert to cuda type\n",
        "# YOUR CODE HERE to define loss and optimizer\n",
        "model = Model().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.01)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F75Z3ABdqvyY"
      },
      "source": [
        "## Training and Testing the model\n",
        "\n",
        "In Training Phase, we iterate over a batch of images in the train_loader. For each batch, we perform  the following steps:\n",
        "\n",
        "* First we zero out the gradients using zero_grad()\n",
        "\n",
        "* We pass the data to the model i.e. we perform forward pass by calling the forward()\n",
        "\n",
        "* We calculate the loss using the actual and predicted labels\n",
        "\n",
        "* Perform Backward pass using backward() to update the weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kG_e4hjdrgs7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45570d3a-f8e6-43df-9d7a-bc8e91f3257f"
      },
      "source": [
        "# No of Epochs\n",
        "epoch = 20\n",
        "\n",
        "# keeping the network in train mode\n",
        "model.train()\n",
        "train_losses,  train_accuracy = [], []\n",
        "val_losses , val_accuracy = [], []\n",
        "\n",
        "# Loop for no of epochs\n",
        "for e in range(epoch):\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    # Iterate through all the batches in each epoch\n",
        "    for images, labels in trainloader:\n",
        "\n",
        "      # Convert the image and label to gpu for faster execution\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # Zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Passing the data to the model (Forward Pass)\n",
        "      outputs = model(images)\n",
        "\n",
        "      # Calculating the loss\n",
        "      loss = criterion(outputs, labels)\n",
        "      train_loss += loss.item()\n",
        "\n",
        "      # Performing backward pass (Backpropagation)\n",
        "      loss.backward()\n",
        "\n",
        "      # optimizer.step() updates the weights accordingly\n",
        "      optimizer.step()\n",
        "\n",
        "      # Accuracy calculation\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_loss = 0\n",
        "    val_correct = 0\n",
        "    with torch.no_grad():\n",
        "        # Loop through all of the validation set\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            val_output = model(images)\n",
        "            val_loss += criterion(val_output, labels)\n",
        "            _, predicted = torch.max(val_output, 1)\n",
        "            val_correct += (predicted == labels).sum()\n",
        "\n",
        "    train_losses.append(train_loss/len(train_set))\n",
        "    val_losses.append(val_loss/len(val_set))\n",
        "    train_accuracy.append(100 * correct/len(train_set))\n",
        "    val_accuracy.append(100 * val_correct/len(val_set))\n",
        "    print('epoch: {}, Train Loss:{:.6f} Validation Loss {:.6f} Train Accuracy: {:.2f}, Validation accuracy {:.2f} '.format(e+1,train_losses[-1], val_losses[-1], train_accuracy[-1], val_accuracy[-1]))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, Train Loss:53.090590 Validation Loss 44.174210 Train Accuracy: 60.25, Validation accuracy 50.33 \n",
            "epoch: 2, Train Loss:27.184241 Validation Loss 10.347517 Train Accuracy: 49.59, Validation accuracy 50.33 \n",
            "epoch: 3, Train Loss:17.530228 Validation Loss 15.100698 Train Accuracy: 50.41, Validation accuracy 56.21 \n",
            "epoch: 4, Train Loss:12.940663 Validation Loss 6.676236 Train Accuracy: 48.77, Validation accuracy 53.59 \n",
            "epoch: 5, Train Loss:13.474373 Validation Loss 5.660836 Train Accuracy: 49.18, Validation accuracy 50.33 \n",
            "epoch: 6, Train Loss:14.078021 Validation Loss 8.463443 Train Accuracy: 52.05, Validation accuracy 56.86 \n",
            "epoch: 7, Train Loss:4.916497 Validation Loss 7.429679 Train Accuracy: 59.43, Validation accuracy 41.83 \n",
            "epoch: 8, Train Loss:5.583433 Validation Loss 7.404654 Train Accuracy: 43.44, Validation accuracy 49.67 \n",
            "epoch: 9, Train Loss:5.720073 Validation Loss 1.283851 Train Accuracy: 54.51, Validation accuracy 50.33 \n",
            "epoch: 10, Train Loss:2.727130 Validation Loss 1.921365 Train Accuracy: 47.95, Validation accuracy 50.33 \n",
            "epoch: 11, Train Loss:0.908701 Validation Loss 0.663805 Train Accuracy: 53.69, Validation accuracy 52.94 \n",
            "epoch: 12, Train Loss:0.733569 Validation Loss 0.543406 Train Accuracy: 52.05, Validation accuracy 44.44 \n",
            "epoch: 13, Train Loss:0.806807 Validation Loss 0.611238 Train Accuracy: 38.11, Validation accuracy 46.41 \n",
            "epoch: 14, Train Loss:0.419914 Validation Loss 0.487204 Train Accuracy: 46.72, Validation accuracy 54.25 \n",
            "epoch: 15, Train Loss:0.507173 Validation Loss 0.468903 Train Accuracy: 61.89, Validation accuracy 54.25 \n",
            "epoch: 16, Train Loss:0.324344 Validation Loss 0.082202 Train Accuracy: 61.07, Validation accuracy 52.94 \n",
            "epoch: 17, Train Loss:0.181640 Validation Loss 0.256941 Train Accuracy: 50.00, Validation accuracy 45.75 \n",
            "epoch: 18, Train Loss:0.229408 Validation Loss 0.022875 Train Accuracy: 37.30, Validation accuracy 55.56 \n",
            "epoch: 19, Train Loss:0.070189 Validation Loss 0.123005 Train Accuracy: 61.48, Validation accuracy 52.94 \n",
            "epoch: 20, Train Loss:0.104981 Validation Loss 0.085761 Train Accuracy: 63.11, Validation accuracy 53.59 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1338yNobnnZ"
      },
      "source": [
        "## Data Augmentation\n",
        "\n",
        "\n",
        "\n",
        "Diversity of data and a larger dataset is the easiest way to avoid overfitting of the model. Data augmentation allows you to increase the size of your dataset by performing processes like flipping, cropping, rotation, scaling and translation on the existing images. Data augmentation not only increases the dataset size but also exposes the model to different angles and lighting and reduces the bias in the dataset, thus avoiding chances of overfitting.\n",
        "\n",
        "Added two more transformations to the original data.\n",
        "\n",
        "\n",
        "*   Applied random rotation of $45^o$ using **`transforms.RandomRotation`**\n",
        "*   Applied vertical flip to the images using **`transforms.RandomVerticalFlip()`**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7hR9B_pbm2g"
      },
      "source": [
        "image_size = (128,128)\n",
        "transformations = transforms.Compose([\n",
        "                                transforms.Resize(image_size),\n",
        "                                transforms.Grayscale(),\n",
        "                                transforms.RandomRotation(45),\n",
        "                                transforms.RandomVerticalFlip(),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,)),\n",
        "                                ])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HdQKsm-bm2i"
      },
      "source": [
        "batch_size = 100\n",
        "\n",
        "# YOUR CODE HERE to load train and validaion data in batches\n",
        "train_set = datasets.ImageFolder('/content/hymenoptera_data/train', transform = transformations)\n",
        "trainloader = torch.utils.data.DataLoader(train_set, batch_size=100, shuffle=True, num_workers=8)\n",
        "\n",
        "val_set = datasets.ImageFolder('/content/hymenoptera_data/val',transform=transformations)\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=100, shuffle=True)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHgEW9-RmdL1"
      },
      "source": [
        "## Regularization\n",
        "\n",
        "Dropouts: Regularization techniques prevent the model from overfitting by modifying the cost function. Dropout, on the other hand, prevents overfitting by modifying the network itself. Every neuron apart from the ones in the output layer is assigned a probability p of being temporarily ignored from calculations. p is also called dropout rate and is initialized to 0.2. Then, as each iteration progresses, the neurons in each layer with the highest probability get dropped. This results in creating a smaller network with each epoch. Since in each iteration, a random input value can be eliminated, the network tries to balance the risk and not to favour any of the features and reduces bias and noise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZAiX592ZeoG"
      },
      "source": [
        "## Optimize the Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et6X_fnFGR3t"
      },
      "source": [
        "class Optimized_Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Optimized_Model, self).__init__()\n",
        "\n",
        "        self.linear1 = nn.Linear(16384,4096)\n",
        "        self.linear2 = nn.Linear(4096,1024)\n",
        "        self.linear3 = nn.Linear(1024,256)\n",
        "        self.linear4 = nn.Linear(256,10)\n",
        "        self.linear5 = nn.Linear(10,2)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "    def forward(self, x):\n",
        "        # YOUR CODE HERE to implement forward pass\n",
        "        out = x.view(x.shape[0],-1)\n",
        "        out = self.linear1(out)\n",
        "        out = self.linear2(out)\n",
        "        out = self.linear3(out)\n",
        "        out = self.linear4(out)\n",
        "        out = self.linear5(out)\n",
        "        return out\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Au6wjEGWZADQ"
      },
      "source": [
        "## Initialize the optimized model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRMMDeiFWlOY"
      },
      "source": [
        "# Instantiate the model\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "# YOUR CODE BELOW to instantiate model and define loss function and optimizer\n",
        "model2= Optimized_Model().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer= optim.Adam(model.parameters(),lr=0.01)\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEmKN7nRvDwm"
      },
      "source": [
        "## Training the optimized model\n",
        "\n",
        "In Training Phase, we iterate over a batch of images in the train_loader. For each batch, we perform  the following steps:\n",
        "\n",
        "* First we zero out the gradients using zero_grad()\n",
        "\n",
        "* We pass the data to the model i.e. we perform forward pass by calling the forward()\n",
        "\n",
        "* We calculate the loss using the actual and predicted labels\n",
        "\n",
        "* Perform Backward pass using backward() to update the weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gt_oZCN3P8rd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "708db4d3-f5e6-4097-8486-25de029e8e2c"
      },
      "source": [
        "# No of Epochs\n",
        "epoch = 20\n",
        "\n",
        "model2.train()\n",
        "train_losses_opt,  train_accuracy_opt = [], []\n",
        "val_losses_opt , val_accuracy_opt = [], []\n",
        "\n",
        "for e in range(epoch):\n",
        "    otrain_loss = 0\n",
        "    ocorrect = 0\n",
        "    # Iterate through all the batches in each epoch\n",
        "    for images, labels in trainloader:\n",
        "\n",
        "      # Convert the image and label to gpu for faster execution\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # Zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      outputs = model2(images)\n",
        "\n",
        "      loss= criterion(outputs,labels)\n",
        "\n",
        "      # YOUR CODE HERE to perform forward pass\n",
        "\n",
        "      # YOUR CODE HERE to Calculate the loss\n",
        "      otrain_loss += loss.item()\n",
        "\n",
        "      # Performing backward pass (Backpropagation)\n",
        "      loss.backward()\n",
        "\n",
        "      # optimizer.step() updates the weights accordingly\n",
        "      optimizer.step()\n",
        "\n",
        "      # YOUR CODE HERE for accuracy calculation\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      ocorrect += (predicted == labels).sum().item()\n",
        "\n",
        "    oval_loss = 0\n",
        "    oval_correct = 0\n",
        "    with torch.no_grad():\n",
        "        # Loop through all of the validation set\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            val_output = model2(images)\n",
        "            oval_loss += criterion(val_output, labels)\n",
        "            _, predicted = torch.max(val_output, 1)\n",
        "            oval_correct += (predicted == labels).sum()\n",
        "            # YOUR CODE HERE to pass the val_images to model, calculate error and accuracy\n",
        "\n",
        "    # YOUR CODE HERE to append all train, validation accuracy and losses\n",
        "    train_losses_opt.append(otrain_loss/len(train_set))\n",
        "    val_losses_opt.append(oval_loss/len(val_set))\n",
        "    train_accuracy_opt.append(100 * ocorrect/len(train_set))\n",
        "    val_accuracy_opt.append(100 * oval_correct/len(val_set))\n",
        "\n",
        "    print('epoch: {}, Train Loss:{:.6f} Test Loss {:.6f} Train Accuracy: {:.2f}, Test accuracy {:.2f} '.format(e+1,train_losses_opt[-1], val_losses_opt[-1], train_accuracy_opt[-1], val_accuracy_opt[-1]))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, Train Loss:0.008562 Test Loss 0.009117 Train Accuracy: 50.41, Test accuracy 45.75 \n",
            "epoch: 2, Train Loss:0.008532 Test Loss 0.009116 Train Accuracy: 50.41, Test accuracy 45.75 \n",
            "epoch: 3, Train Loss:0.008525 Test Loss 0.009180 Train Accuracy: 50.41, Test accuracy 45.75 \n",
            "epoch: 4, Train Loss:0.008530 Test Loss 0.009114 Train Accuracy: 50.41, Test accuracy 45.75 \n",
            "epoch: 5, Train Loss:0.008493 Test Loss 0.009116 Train Accuracy: 50.41, Test accuracy 45.75 \n",
            "epoch: 6, Train Loss:0.008506 Test Loss 0.009157 Train Accuracy: 50.41, Test accuracy 45.75 \n",
            "epoch: 7, Train Loss:0.008543 Test Loss 0.009139 Train Accuracy: 50.41, Test accuracy 45.75 \n",
            "epoch: 8, Train Loss:0.008498 Test Loss 0.009141 Train Accuracy: 50.41, Test accuracy 45.75 \n",
            "epoch: 9, Train Loss:0.008544 Test Loss 0.009215 Train Accuracy: 50.41, Test accuracy 45.75 \n",
            "epoch: 10, Train Loss:0.008528 Test Loss 0.009139 Train Accuracy: 50.41, Test accuracy 45.75 \n",
            "epoch: 11, Train Loss:0.008537 Test Loss 0.009103 Train Accuracy: 50.41, Test accuracy 45.75 \n",
            "epoch: 12, Train Loss:0.008536 Test Loss 0.009130 Train Accuracy: 50.41, Test accuracy 45.75 \n",
            "epoch: 13, Train Loss:0.008568 Test Loss 0.009133 Train Accuracy: 50.41, Test accuracy 45.75 \n",
            "epoch: 14, Train Loss:0.008546 Test Loss 0.009188 Train Accuracy: 50.41, Test accuracy 45.75 \n",
            "epoch: 15, Train Loss:0.008538 Test Loss 0.009134 Train Accuracy: 50.41, Test accuracy 45.75 \n",
            "epoch: 16, Train Loss:0.008544 Test Loss 0.009120 Train Accuracy: 50.41, Test accuracy 45.75 \n",
            "epoch: 17, Train Loss:0.008532 Test Loss 0.009140 Train Accuracy: 50.41, Test accuracy 45.75 \n",
            "epoch: 18, Train Loss:0.008526 Test Loss 0.009197 Train Accuracy: 50.41, Test accuracy 45.75 \n",
            "epoch: 19, Train Loss:0.008509 Test Loss 0.009125 Train Accuracy: 50.41, Test accuracy 45.75 \n",
            "epoch: 20, Train Loss:0.008532 Test Loss 0.009171 Train Accuracy: 50.41, Test accuracy 45.75 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHfHdGCP_n6Y"
      },
      "source": [
        "### Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmvdJ4aNmGjR"
      },
      "source": [
        "#@title State True or False: Using dropout, random neurons in the layer gets deactivated at each training step { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Answer = \"TRUE\" #@param [\"\",\"TRUE\", \"FALSE\"]\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmufjlR-rjv6"
      },
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"Good, But Not Challenging for me\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ7vVuShrjv6"
      },
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"na\" #@param {type:\"string\"}\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VBk_4VTAxCM"
      },
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"Yes\" #@param [\"\",\"Yes\", \"No\"]\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r35isHfTVGKc"
      },
      "source": [
        "#@title  Experiment walkthrough video? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Walkthrough = \"Didn't use\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH91cL1JWH7m"
      },
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"Somewhat Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8xLqj7VWIKW"
      },
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"Didn't use\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzAZHt1zw-Y-",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54374be6-c7ec-4b98-cbbe-9b22bc403d56"
      },
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your submission is successful.\n",
            "Ref Id: 6310\n",
            "Date of submission:  24 Aug 2024\n",
            "Time of submission:  18:57:23\n",
            "View your submissions: https://aiml-iiith.talentsprint.com/notebook_submissions\n"
          ]
        }
      ]
    }
  ]
}