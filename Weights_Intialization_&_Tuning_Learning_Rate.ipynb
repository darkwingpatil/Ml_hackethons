{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/darkwingpatil/Ml_hackethons/blob/main/Weights_Intialization_%26_Tuning_Learning_Rate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlDT2pxVVYIH"
      },
      "source": [
        "# Advanced Certification in AIML\n",
        "## A Program by IIIT-H and TalentSprint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyCF3t5T6k5g"
      },
      "source": [
        "## Learning Objective"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UIQ42UP6nay"
      },
      "source": [
        "At the end of the experiment, you will be able to :\n",
        "\n",
        "1. Understand the role of hyperparameter learning rate\n",
        "2. Observe what happens to the performance of the model when we set learning rate values to high or low\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otjY3N71Psfx"
      },
      "source": [
        "## Experiment walkthrough video"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9TiJI60PtDT"
      },
      "source": [
        "Please refer video explanation of U4W18_64_Weight_InitializationandUpdates for this. This experiment is an extension of the same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mO2VQ0A6oO-"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_m0jyuG6p6K"
      },
      "source": [
        "### Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydFMJSX16uKU"
      },
      "source": [
        "The dataset used for this experiment is CIFAR-100. It  has 100 classes which contains 600 images for each class. There are 500 training images and 100 testing images per class. These 100 classes are grouped into 20 superclasses. Each image comes with the class and superclass it belongs to.\n",
        "\n",
        "Here is the list of classes in the CIFAR-100:\n",
        "\n",
        "| Superclass \t | Classes|\n",
        "|--------------------|-------------|\n",
        "|aquatic mammals | \tbeaver, dolphin, otter, seal, whale |\n",
        "|fish |\taquarium fish, flatfish, ray, shark, trout |\n",
        "|flowers| \torchids, poppies, roses, sunflowers, tulips |\n",
        "|food containers| \tbottles, bowls, cans, cups, plates|\n",
        "|fruit and vegetables| \tapples, mushrooms, oranges, pears, sweet peppers|\n",
        "|household electrical devices | clock, computer keyboard, lamp, telephone, television|\n",
        "|household furniture| \tbed, chair, couch, table, wardrobe|\n",
        "|insects | \tbee, beetle, butterfly, caterpillar, cockroach |\n",
        "|large carnivores| \tbear, leopard, lion, tiger, wolf|\n",
        "|large man-made outdoor things |\tbridge, castle, house, road, skyscraper|\n",
        "|large natural outdoor scenes |\tcloud, forest, mountain, plain, sea|\n",
        "|large omnivores and herbivores |\tcamel, cattle, chimpanzee, elephant, kangaroo|\n",
        "|medium-sized mammals |\tfox, porcupine, possum, raccoon, skunk|\n",
        "|non-insect invertebrates|\tcrab, lobster, snail, spider, worm|\n",
        "|people| \tbaby, boy, girl, man, woman|\n",
        "|reptiles |\tcrocodile, dinosaur, lizard, snake, turtle|\n",
        "|small mammals| \thamster, mouse, rabbit, shrew, squirrel |\n",
        "|trees|\tmaple, oak, palm, pine, willow |\n",
        "|vehicles 1 |\tbicycle, bus, motorcycle, pickup truck, train |\n",
        "|vehicles 2 |\tlawn-mower, rocket, streetcar, tank, tractor |\n",
        "\n",
        "\n",
        "\n",
        "The dataset is downloaded from following url :\n",
        "\n",
        "https://www.cs.toronto.edu/~kriz/cifar.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUBMuYhs6xaN"
      },
      "source": [
        "## AI / ML Technique"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkHCjIwK60x9"
      },
      "source": [
        "### Learning Rate\n",
        "\n",
        "\n",
        "\n",
        "This is the most important hyperparameter to train the neural network. A good learning rate can make a huge difference in between a model that didn't learn anything and a model that learned everything from the data.\n",
        "\n",
        "Let us see some interesting facts about the learning rates :\n",
        "\n",
        "1. While training the model when we observe that the loss is exploding we infer that the value chosen for learning rate is high.\n",
        "2. If we choose learning rate value as too high then there is a chance to overshoot the local minima or good result and in next iteration there is a chance to undershoot the good result.\n",
        "3.  If we choose learning rate value as too low then there is a slow convergence. This can even degrade the performance of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sFKC2BJ63s1"
      },
      "source": [
        "In this experiment we will try to understand how the performance of the model varies when we change the learning rate value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUmaxUW-rpxU"
      },
      "source": [
        "### Setup Steps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcrXxhfmrpxg"
      },
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"2304145\" #@param {type:\"string\"}"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDAfm706rpxg"
      },
      "source": [
        "#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"7892449987\" #@param {type:\"string\"}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "KvdKENTWrpxh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b7e90b25-983e-4a4f-c74d-0778f0639a5c"
      },
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "import re\n",
        "ipython = get_ipython()\n",
        "\n",
        "notebook= \"U4W18_63_Tuning_Hyper_Parameter_Learning_Rate_A\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\")\n",
        "    from IPython.display import HTML, display\n",
        "    ipython.magic(\"sx pip3 install torch\")\n",
        "    ipython.magic(\"sx pip3 install torchvision\")\n",
        "    ipython.magic(\"sx wget https://cdn.talentsprint.com/aiml/Experiment_related_data/week9/Exp6/config.py\")\n",
        "    ipython.magic(\"sx wget https://cdn.talentsprint.com/aiml/Experiment_related_data/week9/Exp6/utils.py\")\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "\n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "\n",
        "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getWalkthrough() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id,\n",
        "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook, \"feedback_walkthrough\":Walkthrough ,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_inclass_mentor\": Mentor_support}\n",
        "\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://aiml-iiith.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "\n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional\n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "\n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getWalkthrough():\n",
        "  try:\n",
        "    if not Walkthrough:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Walkthrough\n",
        "  except NameError:\n",
        "    print (\"Please answer Walkthrough Question\")\n",
        "    return None\n",
        "\n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer():\n",
        "  try:\n",
        "    if not Answer:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Answer\n",
        "  except NameError:\n",
        "    print (\"Please answer Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getId():\n",
        "  try:\n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup\n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup()\n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId=2304145&recordId=7822\"></script>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup completed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTA5H991VYIM"
      },
      "source": [
        "### Importing required Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqStPzYMVYIN"
      },
      "source": [
        "# Importing pytorch packages\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Importing config.py file\n",
        "import config as cf\n",
        "from utils import *\n",
        "\n",
        "# Importing python packages\n",
        "import os\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1fOb-Y_VYIS"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# YOUR CODE HERE: Check for GPU instance (Whether CUDA variable is present or not)\n",
        "# Intilizaing the accuracy value as zero\n",
        "best_acc = 0"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TNoW1Nqop_E",
        "outputId": "6640474d-b9a1-4f44-dced-b488b5798552"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipFKYYbgVYIW"
      },
      "source": [
        "### Preparing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yhn7U19KVYIX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f964ad55-c55d-4626-9293-3ff8e56487ff"
      },
      "source": [
        "print('\\n[Phase 1] : Data Preparation')\n",
        "\n",
        "# Dataset\n",
        "dataset = 'cifar100'\n",
        "\n",
        "# Preparing the dataset\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(cf.mean[dataset], cf.std[dataset]),\n",
        "]) # mean and std transformation\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(cf.mean[dataset], cf.std[dataset]),\n",
        "])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Phase 1] : Data Preparation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qDpWSEHVYIj"
      },
      "source": [
        "#### Downloading and Loading the dataset\n",
        "\n",
        "The torchvision package consists of popular datasets, model architectures, and common image transformations for computer vision.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNGgWJHGVYIk"
      },
      "source": [
        "num_classes = 100\n",
        "# YOUR CODE HERE: Define number of classes are present in the dataset"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz_YvckQVYIo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95f10295-8b6f-46a2-a127-7703332f01df"
      },
      "source": [
        "# Downloading the dataset\n",
        "trainset = torchvision.datasets.CIFAR100(root='data', train=True, download=True, transform=transform_train)\n",
        "testset = torchvision.datasets.CIFAR100(root='data', train=False, download=False, transform=transform_test)\n",
        "\n",
        "# Loading the dataset\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=8)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=8)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169001437/169001437 [00:18<00:00, 9260134.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-100-python.tar.gz to data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  input shape torch.Size([100, 3, 32, 32])\n",
        "# target shape torch.Size([100])\n",
        "\n"
      ],
      "metadata": {
        "id": "qbnVR7Khq51Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5PZj1gdVYIv"
      },
      "source": [
        "### Let us define the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTbr0F0aVYIw"
      },
      "source": [
        "class LeNet(nn.Module):\n",
        "    def __init__(self, num_classes, init_mode='xavier'):  # Supports 'zero', 'normal', 'xavier', 'he' initialization\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1   = nn.Linear(16*5*5, 120)\n",
        "        self.fc2   = nn.Linear(120,84)\n",
        "        # YOUR CODE HERE: Define a linear layer whose input size is 120 and output size is 84\n",
        "        self.fc3   = nn.Linear(84, num_classes)\n",
        "        # YOUR CODE HERE: Define a linear layer whose input size is 84 and output size is equal to the number of classes in the dataset.\n",
        "\n",
        "        if init_mode == 'zero':\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "                     # YOUR CODE HERE: Initialize Weights with zero\n",
        "                     m.weight.data.zero_()\n",
        "                     if m.bias is not None:\n",
        "                        m.bias.data.zero_()\n",
        "                        # YOUR CODE HERE: Initialize bias with zero\n",
        "\n",
        "        if init_mode == 'normal':\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "                    # YOUR CODE HERE: Initialize elements with random numbers from normal distribution\n",
        "                    m.weight.data.normal_()\n",
        "                    if m.bias is not None:\n",
        "                        m.bias.data.normal_()\n",
        "\n",
        "        if init_mode == 'xavier':\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, nn.Conv2d):\n",
        "                    fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                    fan_in = m.kernel_size[0] * m.kernel_size[1] * m.in_channels\n",
        "                    n = fan_in + fan_out\n",
        "                    m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "                    if m.bias is not None:\n",
        "                        m.bias.data.normal_(0, math.sqrt(2. / n))\n",
        "                if isinstance(m, nn.Linear):\n",
        "                    size = m.weight.size()\n",
        "                    fan_out = size[0]\n",
        "                    # YOUR CODE HERE: Define number of rows\n",
        "                    fan_in = size[1]\n",
        "                    # YOUR CODE HERE: Define  number of columns\n",
        "                    variance = math.sqrt(2.0/(fan_in+fan_out))\n",
        "                    m.weight.data.normal_(0.0, variance)\n",
        "                    if m.bias is not None:\n",
        "                        m.bias.data.normal_(0, variance)\n",
        "\n",
        "        if init_mode == 'he':\n",
        "            for m in self.modules():\n",
        "              if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "                if m.bias is not None:\n",
        "                  m.bias.data.normal_(0, math.sqrt(2. / n))\n",
        "              if isinstance(m, nn.Linear):\n",
        "                size = m.weight.size()\n",
        "                fan_out = size[0] # Number of rows\n",
        "                fan_in = size[1] # Number of columns\n",
        "                variance = math.sqrt(2.0/(fan_in))\n",
        "                m.weight.data.normal_(0.0, variance)\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.normal_(0, variance)\n",
        "            # YOUR CODE HERE: Just as above, figure out the mathematical formulation of 'he' initialization and initialize the weights\n",
        "\n",
        "\n",
        "    # Forward Pass\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.conv1(x))\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = F.relu(self.conv2(out))\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = F.relu(self.fc1(out))\n",
        "        out = F.relu(self.fc2(out))\n",
        "        out = self.fc3(out)\n",
        "        return(out)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaBFZzZiVYI0"
      },
      "source": [
        "### Training with Xavier init"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Hn2v9-TVYI2"
      },
      "source": [
        "net = LeNet(num_classes)\n",
        "# YOUR CODE HERE: Call 'LeNet' model defined above\n",
        "\n",
        "net = net.to(device)\n",
        "# YOUR CODE HERE: Convert above defined model object 'net' to CUDA variable"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOR-ZShc2sK4"
      },
      "source": [
        "### Defining the Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dK-JIPDxVYI5"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# YOUR CODE HERE: Intiliazing the loss"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVBUKGoK3Jqo"
      },
      "source": [
        "### Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRbViJdKVYI-"
      },
      "source": [
        "def train(epoch):\n",
        "    # YOUR CODE HERE: To train the network\n",
        "    net.train()\n",
        "    train_loss=0\n",
        "    correct=0\n",
        "    total=0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "\n",
        "        size_ = outputs.size()\n",
        "\n",
        "        # Reducing the dimenssions\n",
        "        outputs_ = outputs.view(size_[0], num_classes)\n",
        "        loss = criterion(outputs_,targets)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        # YOUR CODE HERE: Perform Forward Pass by passing inputs as parameter to the model object 'net' defined above.\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _,predicted = torch.max(outputs_.data,1)\n",
        "\n",
        "        total += targets.size(0)\n",
        "\n",
        "        correct += predicted.eq(targets.data).cpu().sum().item()\n",
        "\n",
        "\n",
        "    # Storing number of epoch,loss and accuracy in a file\n",
        "    print('%d %.3f %.3f\\n' %(epoch, train_loss/len(trainloader), 100.*correct/total),\"accuracy!\")\n",
        "    train_loss_file.write('%d %.3f %.3f\\n' %(epoch, train_loss/len(trainloader), 100.*correct/total))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMEncVnu3M8T"
      },
      "source": [
        "### Testing the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5rNwNEyVYJC"
      },
      "source": [
        "def test(epoch):\n",
        "    global best_acc\n",
        "    net.eval()\n",
        "\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # Looping over test data\n",
        "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        # YOUR CODE HERE: Perform Forward Pass by passing inputs as parameter to the model object 'net' defined above.\n",
        "\n",
        "        # Storing the outputs size\n",
        "        size_ = outputs.size()\n",
        "\n",
        "        # Reducing the dimenssions\n",
        "        outputs_ = outputs.view(size_[0], num_classes)\n",
        "\n",
        "        loss = criterion(outputs_, targets)\n",
        "        # YOUR CODE HERE: Calculate the loss using 'criterion' defined above.\n",
        "\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        # Storing the predicted values\n",
        "        _, predicted = torch.max(outputs_.data, 1)\n",
        "\n",
        "        # Storing the targets size\n",
        "        total += targets.size(0)\n",
        "\n",
        "        # Caluculating the correct values\n",
        "        correct += predicted.eq(targets.data).cpu().sum().item()\n",
        "\n",
        "        # Printing the data\n",
        "        if batch_idx%30 == 0 or batch_idx == len(testloader)-1:\n",
        "            # Printing the progress bar\n",
        "            progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                         % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "    # Printing the validation loss\n",
        "    print('val_loss: ',  test_loss/len(testloader), 'accuracy: ', 100.0*correct/total)\n",
        "    # Storing number of epoch,loss and accuracy in a file\n",
        "    val_loss_file.write('%d %.3f %.3f\\n' %(epoch,  test_loss/len(testloader), 100.*correct/total))\n",
        "\n",
        "    # Save checkpoint.\n",
        "    acc = 100.*correct/total\n",
        "    # Checking for best accuracy\n",
        "    if acc > best_acc:\n",
        "        print('Saving..')\n",
        "        state = {\n",
        "            'net': net,\n",
        "            'acc': acc,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        # Checking whether its a directory or not\n",
        "        if not os.path.isdir('../checkpoint'):\n",
        "            # Creating a directory\n",
        "            os.mkdir('../checkpoint')\n",
        "        # Saving the data\n",
        "        torch.save(state, '../checkpoint_ckpt.t7')\n",
        "        # Storing the best accuracy\n",
        "        best_acc = acc"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9NmsNhxVYJG"
      },
      "source": [
        "experiment = 'lr_schedule'\n",
        "# Creating files in write mode\n",
        "train_loss_file = open(experiment+\"train_loss.txt\", \"w\")\n",
        "val_loss_file = open(experiment+\"val_loss.txt\", \"w\")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w8aNM95VYJL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 963
        },
        "outputId": "8c6cc55e-1299-4159-c735-df67e77fff6f"
      },
      "source": [
        "# Training and testing the model for 60 epochs\n",
        "for epoch in range(0, 60):\n",
        "    if epoch == 50:\n",
        "        optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)\n",
        "    if epoch == 30:\n",
        "        optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "    if epoch == 0:\n",
        "        optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
        "    # Training the model\n",
        "    train(epoch)\n",
        "    # Testing the model\n",
        "    test(epoch)\n",
        "\n",
        "# Closing the files\n",
        "train_loss_file.close()\n",
        "val_loss_file.close()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 3.476 17.428\n",
            " accuracy!\n",
            " [==================================>] | Loss: 3.401 | Acc: 19.370% (1937/10000)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 100/100 \n",
            "val_loss:  3.4010741233825685 accuracy:  19.37\n",
            "Saving..\n",
            "1 3.282 20.562\n",
            " accuracy!\n",
            " [==================================>] | Loss: 3.241 | Acc: 21.490% (2149/10000)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 100/100 \n",
            "val_loss:  3.2413515758514406 accuracy:  21.49\n",
            "Saving..\n",
            "2 3.142 22.966\n",
            " accuracy!\n",
            " [==================================>] | Loss: 3.138 | Acc: 23.680% (2368/10000)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 100/100 \n",
            "val_loss:  3.1383903431892395 accuracy:  23.68\n",
            "Saving..\n",
            "3 3.037 25.240\n",
            " accuracy!\n",
            " [==================================>] | Loss: 3.116 | Acc: 23.460% (2346/10000)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 100/100 \n",
            "val_loss:  3.1158916187286376 accuracy:  23.46\n",
            "4 2.952 26.592\n",
            " accuracy!\n",
            " [==================================>] | Loss: 3.027 | Acc: 25.280% (2528/10000)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 100/100 \n",
            "val_loss:  3.026536271572113 accuracy:  25.28\n",
            "Saving..\n",
            "5 2.878 28.104\n",
            " accuracy!\n",
            " [==================================>] | Loss: 2.943 | Acc: 27.580% (2758/10000)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 100/100 \n",
            "val_loss:  2.9433870625495913 accuracy:  27.58\n",
            "Saving..\n",
            "6 2.818 29.042\n",
            " accuracy!\n",
            " [==================================>] | Loss: 2.874 | Acc: 28.230% (2823/10000)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 100/100 \n",
            "val_loss:  2.87374605178833 accuracy:  28.23\n",
            "Saving..\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-22065ebe8ed9>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Training the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Testing the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-0269febbfc9e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDMll3RCVYJR"
      },
      "source": [
        "### Plotting the training curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRLIKRPpVYJT"
      },
      "source": [
        "training_curves(experiment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHfHdGCP_n6Y"
      },
      "source": [
        "### Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmvdJ4aNmGjR"
      },
      "source": [
        "#@title State True or False: In the experiemnt above, as epochs increase, the learning rate value is increased ? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Answer = \"TRUE\" #@param [\"\",\"TRUE\", \"FALSE\"]\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmufjlR-rjv6"
      },
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"Good and Challenging for me\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ7vVuShrjv6"
      },
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"na\" #@param {type:\"string\"}\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VBk_4VTAxCM"
      },
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"No\" #@param [\"\",\"Yes\", \"No\"]\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r35isHfTVGKc"
      },
      "source": [
        "#@title  Experiment walkthrough video? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Walkthrough = \"Not Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH91cL1JWH7m"
      },
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"Somewhat Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8xLqj7VWIKW"
      },
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"Didn't use\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzAZHt1zw-Y-",
        "cellView": "form",
        "outputId": "3e40827f-f33e-4aa1-c18a-eb35afbad1b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your submission is successful.\n",
            "Ref Id: 7822\n",
            "Date of submission:  28 Sep 2024\n",
            "Time of submission:  19:41:31\n",
            "View your submissions: https://aiml-iiith.talentsprint.com/notebook_submissions\n"
          ]
        }
      ]
    }
  ]
}